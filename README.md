# Earth ğŸŒ

A synthetic data generation platform for analytics engineering and machine learning experimentation.

## Purpose

Earth enables downstream analytics and machine learning by generating realistic, incremental synthetic datasets. Built with modern data engineering best practices, Earth provides a foundation for testing data pipelines, developing ML models, and experimenting with analytics workflows using synthetic person profiles and time-series data.

## Technology Stack

| Stage                   | Technologies                                                                                                                                                                                              |
| ----------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Data Generation**     | ![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white) ![Faker](https://img.shields.io/badge/Faker-FF6B6B?style=for-the-badge&logo=python&logoColor=white) |
| **Data Storage**        | ![DuckDB](https://img.shields.io/badge/DuckDB-FFF000?style=for-the-badge&logo=duckdb&logoColor=black)                                                                                                     |
| **Data Processing**     | ![Pandas](https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white)                                                                                                     |
| **Data Transformation** | ![dbt](https://img.shields.io/badge/dbt-FF694B?style=for-the-badge&logo=dbt&logoColor=white)                                                                                                              |
| **Orchestration**       | ![Prefect](https://img.shields.io/badge/Prefect-026AA7?style=for-the-badge&logo=prefect&logoColor=white)                                                                                                  |

## Architecture

```bash
earth/
â”œâ”€â”€ README.md
â”œâ”€â”€ CHANGELOG.md
â”œâ”€â”€ LICENSE
â”œâ”€â”€ pyproject.toml                   # Build
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Makefile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.sh                         # Installation shell script
â”‚
â”œâ”€â”€ .github/
â”‚   â”œâ”€â”€ workflows/
â”‚   â”‚   â”œâ”€â”€ ci.yml
â”‚   â”‚   â”œâ”€â”€ release-please.yml
â”‚   â”‚   â””â”€â”€ test-publish.yml
â”‚   â””â”€â”€ release-please-config.json
â”‚
â”œâ”€â”€ app/                             # Application layer
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                      # â† Primary orchestrator
â”‚   â””â”€â”€ workflows/                   # Application-specific workflows
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ base.py                  # Base classes and patterns for scalable workflow management
â”‚       â”œâ”€â”€ config.py                # Workflow config metadata e.g. available workflows, templates
â”‚       â”œâ”€â”€ base.py                  # Abstract base workflow generation class
â”‚       â”œâ”€â”€ dataset_orchestrator.py  # Coordinate workflow executions
â”‚       â””â”€â”€ unified_workflow.py      # Unified workflow using base generator
â”‚
â”œâ”€â”€ src/                             # Package source for PyPI
â”‚   â””â”€â”€ earth/                       # The installable package
â”‚       â”œâ”€â”€ __init__.py              # Package entry point
â”‚       â”œâ”€â”€ core/                    # Core functionality
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ loader.py            # DuckDB interface & CRUD
â”‚       â”‚   â”œâ”€â”€ utils.py             # Utilities and constants
â”‚       â”‚   â””â”€â”€ database.py          # Database schema management
â”‚       â”œâ”€â”€ generators/              # Data generators
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ base.py              # Base generator class
â”‚       â”‚   â”œâ”€â”€ factory.py           # Factory class for creating generators
â”‚       â”‚   â”œâ”€â”€ person.py            # Person generator
â”‚       â”‚   â”œâ”€â”€ company.py           # Company generator
â”‚       â”‚   â””â”€â”€ career.py            # Career generator
â”‚       â””â”€â”€ modules/                 # Optional modules [TBD]
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ companies/
â”‚           â”‚   â”œâ”€â”€ __init__.py
â”‚           â”‚   â”œâ”€â”€ generator.py
â”‚           â”‚   â”œâ”€â”€ industries.py
â”‚           â”‚   â””â”€â”€ schemas.py
â”‚           â”œâ”€â”€ campaigns/
â”‚           â”‚   â”œâ”€â”€ __init__.py
â”‚           â”‚   â”œâ”€â”€ generator.py
â”‚           â”‚   â”œâ”€â”€ products.py
â”‚           â”‚   â”œâ”€â”€ brands.py
â”‚           â”‚   â””â”€â”€ schemas.py
â”‚           â””â”€â”€ automotive/
â”‚               â”œâ”€â”€ __init__.py
â”‚               â”œâ”€â”€ generator.py
â”‚               â”œâ”€â”€ vehicles.py
â”‚               â””â”€â”€ schemas.py
â”‚
â”œâ”€â”€ logs/                            # Application logs
â”‚   â””â”€â”€ loader/                      # Loader-specific logs
â”‚
â”œâ”€â”€ tests/                           # Test suite
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_core/
â”‚   â”‚   â”œâ”€â”€ test_loader.py
â”‚   â”‚   â””â”€â”€ test_utils.py
â”‚   â”œâ”€â”€ test_generators/
â”‚   â”‚   â”œâ”€â”€ test_person.py
â”‚   â”‚   â””â”€â”€ test_career.py
â”‚   â”œâ”€â”€ test_modules/
â”‚   â”‚   â”œâ”€â”€ test_companies/
â”‚   â”‚   â”œâ”€â”€ test_campaigns/
â”‚   â”‚   â””â”€â”€ test_automotive/
â”‚   â””â”€â”€ test_app/                    # Test the application layer
â”‚       â”œâ”€â”€ test_main.py
â”‚       â””â”€â”€ test_workflows.py
â”‚
â”œâ”€â”€ docs/                            # Documentation
â”‚   â”œâ”€â”€ index.md
â”‚   â”œâ”€â”€ installation.md
â”‚   â”œâ”€â”€ application-usage.md         # How to use app/main.py
â”‚   â”œâ”€â”€ package-usage.md             # How to use as pip package
â”‚   â”œâ”€â”€ modules/
â”‚   â””â”€â”€ examples/
â”‚       â”œâ”€â”€ generate_150k_people.py
â”‚       â”œâ”€â”€ package_usage.py
â”‚       â””â”€â”€ application_usage.py
â”‚
â””â”€â”€ data/                           # Optional: Sample data or schemas
    â”œâ”€â”€ schemas/
    â”‚   â”œâ”€â”€ person.sql
    â”‚   â”œâ”€â”€ companies.sql
    â”‚   â””â”€â”€ campaigns.sql
    â””â”€â”€ samples/
        â””â”€â”€ sample_output.parquet
```

## How to Use Locally

### Prerequisites

- Python 3.9+
- pip or poetry

### Installation [WIP]

```bash
# Clone repository
git clone https://github.com/ChrisAdan/earth
cd earth

# Install package in development mode
pip install -e ./src

# Install dependencies
pip install pandas duckdb faker dbt-duckdb prefect
```

### Quick Start

```bash
# Generate synthetic person profiles
python app/main.py

# Follow prompts to:
# - Specify number of records to generate
# - Choose append vs. overwrite existing data
```

### Database Schema [WIP]

The `earth.duckdb` database will be created automatically with the following structure:

- `raw.persons` - Synthetic person profiles with demographic and contact information

## Technology Glossary

**DuckDB**: An in-process SQL OLAP database management system optimized for analytics workloads. Provides fast analytical query performance with minimal setup.

**Faker**: A Python library for generating fake but realistic data. Used to create synthetic person profiles, addresses, and other demographic information.

**dbt**: Data Build Tool for transforming data in warehouses using SQL and Jinja templating. Enables version-controlled, tested data transformations.

**Prefect**: Modern workflow orchestration framework for building, scheduling, and monitoring data pipelines with Python.

## Roadmap

### Stage 1: Foundation âœ…

- [âœ…] Core database architecture with DuckDB
- [âœ…] Person profile generation with Faker
- [âœ…] CRUD operations and logging infrastructure
- [âœ…] Interactive CLI for data generation

### Stage 2: Enhanced Entities ğŸš§

- [ ] Additional entity generators (companies, products, transactions)
- [ ] Relationship mapping between entities
- [ ] Data quality validation and constraints

### Stage 3: Time Series Integration ğŸ“…

- [ ] Temporal data generation patterns
- [ ] Event-based data simulation
- [ ] Historical data backfilling capabilities

### Stage 4: External API Integration ğŸŒ

- [ ] TMDB API integration for entertainment data
- [ ] Synthetic person-to-event mapping
- [ ] Weather and location-based data enrichment

### Stage 5: Advanced Analytics ğŸ“Š

- [ ] dbt transformation models
- [ ] Data marts for common analytics patterns
- [ ] ML feature engineering pipelines

### Stage 6: Production Orchestration ğŸ”„

- [ ] Prefect workflow implementation
- [ ] Automated incremental data generation
- [ ] Data quality monitoring and alerting

## Stay Connected

[![Read On](https://img.shields.io/badge/Read%20On-Medium-12100E?style=for-the-badge&logo=medium&logoColor=white)](https://www.linkedin.com/in/chrisadan/)
[![Connect On](https://img.shields.io/badge/Connect%20On-LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/chrisadan/)
